{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ebb5520",
   "metadata": {},
   "source": [
    "# Step One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eebed8d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary:\n",
      "['', '[UNK]', 'i', 'love', 'learning', 'programming', 'enjoy', 'deep', 'machine']\n",
      "\n",
      "Vectorized Data (Sequences):\n",
      "tf.Tensor(\n",
      "[[2 3 8 4]\n",
      " [2 3 7 4]\n",
      " [2 6 7 4]\n",
      " [2 6 5 0]\n",
      " [2 3 5 0]], shape=(5, 4), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "# Sample sentences\n",
    "sentences = [\n",
    "    'i love machine learning',\n",
    "    'i love deep learning',\n",
    "    'i enjoy deep learning',\n",
    "    'i enjoy programming',\n",
    "    'i love programming'\n",
    "]\n",
    "\n",
    "# Create a TextVectorization layer\n",
    "# max_tokens: The maximum size of the vocabulary.\n",
    "# output_sequence_length: The length of the output sequences.\n",
    "vectorize_layer = keras.layers.TextVectorization(\n",
    "    max_tokens=10, \n",
    "    output_sequence_length=4\n",
    ")\n",
    "\n",
    "# Adapt the layer to your data\n",
    "# This is where the vocabulary is built\n",
    "vectorize_layer.adapt(sentences)\n",
    "\n",
    "# Convert sentences to integer sequences\n",
    "vectorized_data = vectorize_layer(tf.constant(sentences))\n",
    "\n",
    "print(\"Vocabulary:\")\n",
    "print(vectorize_layer.get_vocabulary())\n",
    "print(\"\\nVectorized Data (Sequences):\")\n",
    "print(vectorized_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e82c4bcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ text_vectorization_1            │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TextVectorization</span>)             │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ text_vectorization_1            │ (\u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m4\u001b[0m)                 │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mTextVectorization\u001b[0m)             │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.layers import Embedding\n",
    "    \n",
    "# Get the vocabulary size and embedding dimension\n",
    "vocab_size = vectorize_layer.vocabulary_size()\n",
    "embedding_dim = 64  # This is a hyperparameter you can tune\n",
    "\n",
    "# Create a simple model\n",
    "model = keras.Sequential([\n",
    "    vectorize_layer,  # The TextVectorization layer we created earlier\n",
    "    Embedding(\n",
    "        input_dim=vocab_size,\n",
    "        output_dim=embedding_dim,\n",
    "    )\n",
    "])\n",
    "\n",
    "# Print a summary of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "009c0b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of word embeddings: (5, 4, 64)\n",
      "Embedding vectors:\n",
      " tf.Tensor(\n",
      "[[[-0.02905157 -0.02192582 -0.02985046 ... -0.00763953  0.02562919\n",
      "    0.01993114]\n",
      "  [-0.02469324  0.0156658   0.01142956 ... -0.02961923  0.00948169\n",
      "   -0.03707187]\n",
      "  [-0.04378277 -0.03771529 -0.03158895 ... -0.04505865  0.04770208\n",
      "    0.02161039]\n",
      "  [ 0.00507027 -0.01211816  0.04651357 ...  0.016757    0.04183363\n",
      "    0.00303914]]\n",
      "\n",
      " [[-0.02905157 -0.02192582 -0.02985046 ... -0.00763953  0.02562919\n",
      "    0.01993114]\n",
      "  [-0.02469324  0.0156658   0.01142956 ... -0.02961923  0.00948169\n",
      "   -0.03707187]\n",
      "  [ 0.04145371  0.03068919 -0.00516153 ...  0.0254828   0.03504975\n",
      "   -0.00499316]\n",
      "  [ 0.00507027 -0.01211816  0.04651357 ...  0.016757    0.04183363\n",
      "    0.00303914]]\n",
      "\n",
      " [[-0.02905157 -0.02192582 -0.02985046 ... -0.00763953  0.02562919\n",
      "    0.01993114]\n",
      "  [ 0.02555398  0.0413499  -0.01618407 ... -0.02444042  0.0494576\n",
      "   -0.00528054]\n",
      "  [ 0.04145371  0.03068919 -0.00516153 ...  0.0254828   0.03504975\n",
      "   -0.00499316]\n",
      "  [ 0.00507027 -0.01211816  0.04651357 ...  0.016757    0.04183363\n",
      "    0.00303914]]\n",
      "\n",
      " [[-0.02905157 -0.02192582 -0.02985046 ... -0.00763953  0.02562919\n",
      "    0.01993114]\n",
      "  [ 0.02555398  0.0413499  -0.01618407 ... -0.02444042  0.0494576\n",
      "   -0.00528054]\n",
      "  [ 0.01840055 -0.0241099  -0.01728237 ... -0.00878464  0.03089688\n",
      "   -0.01399257]\n",
      "  [ 0.03373757  0.03471975 -0.00314801 ...  0.02542828  0.03548681\n",
      "   -0.04453933]]\n",
      "\n",
      " [[-0.02905157 -0.02192582 -0.02985046 ... -0.00763953  0.02562919\n",
      "    0.01993114]\n",
      "  [-0.02469324  0.0156658   0.01142956 ... -0.02961923  0.00948169\n",
      "   -0.03707187]\n",
      "  [ 0.01840055 -0.0241099  -0.01728237 ... -0.00878464  0.03089688\n",
      "   -0.01399257]\n",
      "  [ 0.03373757  0.03471975 -0.00314801 ...  0.02542828  0.03548681\n",
      "   -0.04453933]]], shape=(5, 4, 64), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Create a dummy input to get the output of the embedding layer\n",
    "sample_input = tf.constant(sentences)\n",
    "# Pass the input through the model to get the embedding vectors\n",
    "word_embeddings = model(sample_input)\n",
    "\n",
    "# Print the shape and first few embedding vectors\n",
    "print(\"Shape of word embeddings:\", word_embeddings.shape)\n",
    "print(\"Embedding vectors:\\n\", word_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed25fe3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ text_vectorization              │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TextVectorization</span>)             │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d        │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ text_vectorization              │ (\u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m4\u001b[0m)                 │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mTextVectorization\u001b[0m)             │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d        │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 655ms/step - accuracy: 0.2500 - loss: 0.6980 - val_accuracy: 1.0000 - val_loss: 0.6802 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.5000 - loss: 0.6951 - val_accuracy: 1.0000 - val_loss: 0.6813 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.7500 - loss: 0.6922 - val_accuracy: 1.0000 - val_loss: 0.6824 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 0.6893 - val_accuracy: 1.0000 - val_loss: 0.6835 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 0.6864 - val_accuracy: 1.0000 - val_loss: 0.6846 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 0.6835 - val_accuracy: 1.0000 - val_loss: 0.6857 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 0.6807 - val_accuracy: 1.0000 - val_loss: 0.6859 - learning_rate: 2.0000e-04\n",
      "Epoch 8/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 0.6801 - val_accuracy: 1.0000 - val_loss: 0.6861 - learning_rate: 2.0000e-04\n",
      "Epoch 9/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 0.6795 - val_accuracy: 1.0000 - val_loss: 0.6863 - learning_rate: 2.0000e-04\n",
      "Epoch 10/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.6789 - val_accuracy: 1.0000 - val_loss: 0.6865 - learning_rate: 2.0000e-04\n",
      "Epoch 11/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 0.6784 - val_accuracy: 1.0000 - val_loss: 0.6867 - learning_rate: 2.0000e-04\n"
     ]
    }
   ],
   "source": [
    "# We need labels for classification\n",
    "labels = tf.constant([0, 0, 1, 1, 0]) # 0 for \"learning\", 1 for \"programming\"\n",
    "\n",
    "# A simple classification model\n",
    "classification_model = keras.Sequential([\n",
    "    vectorize_layer,\n",
    "    keras.layers.Embedding(\n",
    "        input_dim=vocab_size,\n",
    "        output_dim=embedding_dim\n",
    "    ),\n",
    "    keras.layers.GlobalAveragePooling1D(), # A layer to reduce the dimensions\n",
    "    keras.layers.Dense(1, activation='sigmoid') # A dense layer for binary classification\n",
    "])\n",
    "\n",
    "classification_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "classification_model.summary()\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True, monitor=\"val_loss\"),\n",
    "    keras.callbacks.ReduceLROnPlateau(patience=5, factor=0.2, monitor=\"val_loss\")\n",
    "]\n",
    "\n",
    "# Train the model\n",
    "history = classification_model.fit(\n",
    "    tf.constant(sentences),\n",
    "    labels,\n",
    "    epochs=100,\n",
    "    callbacks=callbacks,\n",
    "    validation_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ccefd2",
   "metadata": {},
   "source": [
    "# Step Two /  Semantic Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0b727e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences loaded: 1000\n",
      "\n",
      "First sentence:\n",
      "This was an absolutely terrible movie. Don't be lured in by Christopher Walken or Michael Ironside. Both are great actors, but this must simply be their worst role in history. Even their great acting could not redeem this movie's ridiculous storyline. This movie is an early nineties US propaganda piece. The most pathetic scenes were those when the Columbian rebels were making their cases for revolutions. Maria Conchita Alonso appeared phony, and her pseudo-love affair with Walken was nothing but a pathetic emotional plug in a movie that was devoid of any real meaning. I am disappointed that there are movies like this, ruining actor's like Christopher Walken's good name. I could barely sit through it.\n",
      "\n",
      "First label:\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "\n",
    "# Load a small sample of the IMDb movie reviews\n",
    "# We'll use the 'train' split to get more sentences for embedding\n",
    "ds = tfds.load('imdb_reviews', split='train[:1000]', as_supervised=True)\n",
    "# Convert Bytes (in TensorFlow Dataset Format) to Strings\n",
    "sentences = [text.decode('utf-8') for text, _ in tfds.as_numpy(ds)]\n",
    "labels = [label for _, label in tfds.as_numpy(ds)]\n",
    "\n",
    "# We'll take the first 100 sentences for our project\n",
    "sentences_subset = np.array(sentences[:100])\n",
    "labels_subset = np.array(labels[:100])\n",
    "\n",
    "print(f\"Number of sentences loaded: {len(sentences)}\")\n",
    "print(\"\\nFirst sentence:\")\n",
    "print(sentences_subset[0])\n",
    "print(\"\\nFirst label:\")\n",
    "print(labels_subset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5cba4106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in vocabulary: 4759\n",
      "\n",
      "First 3 vectorized sentences:\n",
      "tf.Tensor(\n",
      "[[  10   17   31  292  398   21   79   27 3146    8   36  997 1084   44\n",
      "   419 3339  236   23  101   93   20   10  230  184   27   57  240  200\n",
      "     8  654   74   57  101  162   92   29 2558   10   62  810 1169   10\n",
      "    21    7   31  368 2942  163 1271  414    2   68  833  104   76  128\n",
      "    48    2 4226 2576   76  504   57 1639   15 2492 3117 4191 4638  382\n",
      "  2778    3   35 2648 4674   14 1084   17  114   20    5  833  538 2739\n",
      "     8    5   21   12   17 3994    4   85  130 3091    9  260  541   12\n",
      "    52   23   62   45   10 2453   93   45  997 1864   49  306    9   92\n",
      "  1026  602  153   11    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0]\n",
      " [   9   22   89  355    6  679 1695  315   90   20   10    7  577  687\n",
      "     6    5 1619    4  241  896   88  763  112 1080    3  990   25    2\n",
      "  2374    3  192   32 3893    5  158  252   25   10 2891    9  931 1695\n",
      "   160    2   19   17 2456    2  105  694   17 1609 1608  788    3 1015\n",
      "   241  299    6  521   20   14   50  938    4   47   17 4326   59   44\n",
      "   120    9 1723    9  216   22  499  201    4    2   19   20    9  390\n",
      "     2 3131    4   11    3  438   32  299    6  521    4   40  123 4703\n",
      "   181   85  130 4194   15  323  313    9  257  343   10   19   33   28\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0]], shape=(2, 256), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.layers import Dense, Embedding, Input, LSTM, TextVectorization, GlobalAveragePooling1D\n",
    "from keras import Sequential\n",
    "\n",
    "vectorize_layer = TextVectorization(max_tokens=10000, output_mode='int', output_sequence_length=256)\n",
    "# Adapt the layer to our dataset. This is where the layer learns the vocabulary.\n",
    "vectorize_layer.adapt(tf.constant(sentences_subset))\n",
    "\n",
    "# Convert the sentences to vectorized data (sequences of integers)\n",
    "vectorized_data = vectorize_layer(tf.constant(sentences_subset))\n",
    "\n",
    "print(f\"Number of words in vocabulary: {len(vectorize_layer.get_vocabulary())}\")\n",
    "print(\"\\nFirst 3 vectorized sentences:\")\n",
    "print(vectorized_data[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "85a2793c",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 128\n",
    "# we should get the vocabulary size because may its size < max_tokens_size\n",
    "vocab_size = vectorize_layer.vocabulary_size()\n",
    "\n",
    "model = Sequential(\n",
    "    [\n",
    "        Embedding(\n",
    "            input_dim=vocab_size,\n",
    "            output_dim=embedding_dim,\n",
    "            mask_zero=True,  # The `mask_zero=True` argument helps the model ignore the padding zeros.\n",
    "            name=\"embedding_layer\"\n",
    "        ),\n",
    "        GlobalAveragePooling1D(),\n",
    "        Dense(1, activation=\"sigmoid\"),  # A simple dense layer for a dummy task\n",
    "    ]\n",
    ")\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a2191194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.0460 - val_accuracy: 0.6000 - val_loss: 0.6442\n",
      "Epoch 2/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0449 - val_accuracy: 0.6000 - val_loss: 0.6438\n",
      "Epoch 3/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0438 - val_accuracy: 0.6000 - val_loss: 0.6435\n",
      "Epoch 4/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0429 - val_accuracy: 0.6000 - val_loss: 0.6431\n",
      "Epoch 5/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0419 - val_accuracy: 0.6000 - val_loss: 0.6427\n",
      "Epoch 6/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0410 - val_accuracy: 0.6000 - val_loss: 0.6423\n",
      "Epoch 7/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0401 - val_accuracy: 0.6000 - val_loss: 0.6419\n",
      "Epoch 8/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0392 - val_accuracy: 0.6000 - val_loss: 0.6416\n",
      "Epoch 9/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0383 - val_accuracy: 0.6000 - val_loss: 0.6413\n",
      "Epoch 10/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0375 - val_accuracy: 0.6000 - val_loss: 0.6409\n",
      "Epoch 11/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0367 - val_accuracy: 0.6000 - val_loss: 0.6404\n",
      "Epoch 12/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0359 - val_accuracy: 0.6000 - val_loss: 0.6398\n",
      "Epoch 13/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0352 - val_accuracy: 0.6000 - val_loss: 0.6392\n",
      "Epoch 14/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0344 - val_accuracy: 0.6000 - val_loss: 0.6386\n",
      "Epoch 15/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0338 - val_accuracy: 0.6000 - val_loss: 0.6380\n",
      "Epoch 16/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0330 - val_accuracy: 0.6000 - val_loss: 0.6376\n",
      "Epoch 17/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0324 - val_accuracy: 0.6000 - val_loss: 0.6371\n",
      "Epoch 18/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0317 - val_accuracy: 0.6000 - val_loss: 0.6367\n",
      "Epoch 19/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0311 - val_accuracy: 0.6000 - val_loss: 0.6362\n",
      "Epoch 20/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0304 - val_accuracy: 0.6000 - val_loss: 0.6359\n",
      "Epoch 21/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0299 - val_accuracy: 0.6000 - val_loss: 0.6355\n",
      "Epoch 22/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0293 - val_accuracy: 0.6000 - val_loss: 0.6352\n",
      "Epoch 23/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0287 - val_accuracy: 0.6000 - val_loss: 0.6347\n",
      "Epoch 24/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 0.0282 - val_accuracy: 0.6000 - val_loss: 0.6343\n",
      "Epoch 25/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 0.0276 - val_accuracy: 0.6000 - val_loss: 0.6338\n",
      "Epoch 26/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0271 - val_accuracy: 0.6000 - val_loss: 0.6333\n",
      "Epoch 27/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 0.0266 - val_accuracy: 0.6000 - val_loss: 0.6329\n",
      "Epoch 28/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0261 - val_accuracy: 0.6000 - val_loss: 0.6326\n",
      "Epoch 29/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0256 - val_accuracy: 0.6000 - val_loss: 0.6323\n",
      "Epoch 30/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0252 - val_accuracy: 0.6000 - val_loss: 0.6321\n",
      "Epoch 31/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0247 - val_accuracy: 0.6000 - val_loss: 0.6318\n",
      "Epoch 32/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0243 - val_accuracy: 0.6000 - val_loss: 0.6315\n",
      "Epoch 33/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0238 - val_accuracy: 0.6000 - val_loss: 0.6311\n",
      "Epoch 34/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0234 - val_accuracy: 0.6000 - val_loss: 0.6308\n",
      "Epoch 35/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0230 - val_accuracy: 0.6000 - val_loss: 0.6306\n",
      "Epoch 36/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0226 - val_accuracy: 0.6000 - val_loss: 0.6303\n",
      "Epoch 37/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0222 - val_accuracy: 0.6000 - val_loss: 0.6301\n",
      "Epoch 38/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0219 - val_accuracy: 0.6000 - val_loss: 0.6299\n",
      "Epoch 39/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 0.0215 - val_accuracy: 0.6000 - val_loss: 0.6298\n",
      "Epoch 40/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0211 - val_accuracy: 0.6000 - val_loss: 0.6295\n",
      "Epoch 41/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0208 - val_accuracy: 0.6000 - val_loss: 0.6294\n",
      "Epoch 42/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0204 - val_accuracy: 0.6000 - val_loss: 0.6293\n",
      "Epoch 43/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0201 - val_accuracy: 0.6000 - val_loss: 0.6291\n",
      "Epoch 44/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0198 - val_accuracy: 0.6000 - val_loss: 0.6289\n",
      "Epoch 45/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0195 - val_accuracy: 0.6000 - val_loss: 0.6286\n",
      "Epoch 46/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0192 - val_accuracy: 0.6000 - val_loss: 0.6284\n",
      "Epoch 47/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0189 - val_accuracy: 0.6000 - val_loss: 0.6282\n",
      "Epoch 48/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0186 - val_accuracy: 0.6000 - val_loss: 0.6281\n",
      "Epoch 49/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0183 - val_accuracy: 0.6000 - val_loss: 0.6280\n",
      "Epoch 50/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0180 - val_accuracy: 0.6000 - val_loss: 0.6278\n",
      "Epoch 51/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0177 - val_accuracy: 0.6000 - val_loss: 0.6276\n",
      "Epoch 52/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0175 - val_accuracy: 0.6000 - val_loss: 0.6274\n",
      "Epoch 53/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0172 - val_accuracy: 0.6000 - val_loss: 0.6272\n",
      "Epoch 54/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0169 - val_accuracy: 0.6000 - val_loss: 0.6270\n",
      "Epoch 55/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0167 - val_accuracy: 0.6000 - val_loss: 0.6268\n",
      "Epoch 56/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0165 - val_accuracy: 0.6000 - val_loss: 0.6267\n",
      "Epoch 57/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0162 - val_accuracy: 0.6000 - val_loss: 0.6267\n",
      "Epoch 58/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 0.0160 - val_accuracy: 0.6000 - val_loss: 0.6266\n",
      "Epoch 59/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0157 - val_accuracy: 0.6000 - val_loss: 0.6264\n",
      "Epoch 60/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0155 - val_accuracy: 0.6000 - val_loss: 0.6262\n",
      "Epoch 61/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0153 - val_accuracy: 0.6000 - val_loss: 0.6259\n",
      "Epoch 62/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0151 - val_accuracy: 0.6000 - val_loss: 0.6257\n",
      "Epoch 63/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0149 - val_accuracy: 0.6000 - val_loss: 0.6254\n",
      "Epoch 64/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0147 - val_accuracy: 0.6000 - val_loss: 0.6251\n",
      "Epoch 65/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0145 - val_accuracy: 0.6000 - val_loss: 0.6249\n",
      "Epoch 66/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 0.0143 - val_accuracy: 0.6000 - val_loss: 0.6247\n",
      "Epoch 67/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0141 - val_accuracy: 0.6000 - val_loss: 0.6245\n",
      "Epoch 68/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0139 - val_accuracy: 0.6000 - val_loss: 0.6244\n",
      "Epoch 69/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0137 - val_accuracy: 0.6000 - val_loss: 0.6243\n",
      "Epoch 70/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0135 - val_accuracy: 0.6000 - val_loss: 0.6242\n",
      "Epoch 71/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0133 - val_accuracy: 0.6000 - val_loss: 0.6241\n",
      "Epoch 72/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0131 - val_accuracy: 0.6000 - val_loss: 0.6240\n",
      "Epoch 73/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0130 - val_accuracy: 0.6000 - val_loss: 0.6239\n",
      "Epoch 74/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0128 - val_accuracy: 0.6000 - val_loss: 0.6238\n",
      "Epoch 75/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0126 - val_accuracy: 0.6000 - val_loss: 0.6237\n",
      "Epoch 76/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0125 - val_accuracy: 0.6000 - val_loss: 0.6237\n",
      "Epoch 77/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0123 - val_accuracy: 0.6000 - val_loss: 0.6236\n",
      "Epoch 78/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0122 - val_accuracy: 0.6000 - val_loss: 0.6236\n",
      "Epoch 79/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0120 - val_accuracy: 0.6000 - val_loss: 0.6235\n",
      "Epoch 80/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0119 - val_accuracy: 0.6000 - val_loss: 0.6235\n",
      "Epoch 81/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0117 - val_accuracy: 0.6000 - val_loss: 0.6234\n",
      "Epoch 82/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 0.0116 - val_accuracy: 0.6000 - val_loss: 0.6232\n",
      "Epoch 83/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0114 - val_accuracy: 0.6000 - val_loss: 0.6230\n",
      "Epoch 84/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0113 - val_accuracy: 0.6000 - val_loss: 0.6229\n",
      "Epoch 85/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0111 - val_accuracy: 0.6000 - val_loss: 0.6227\n",
      "Epoch 86/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0110 - val_accuracy: 0.6000 - val_loss: 0.6226\n",
      "Epoch 87/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0109 - val_accuracy: 0.6000 - val_loss: 0.6225\n",
      "Epoch 88/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0107 - val_accuracy: 0.6000 - val_loss: 0.6224\n",
      "Epoch 89/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0106 - val_accuracy: 0.6000 - val_loss: 0.6223\n",
      "Epoch 90/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0105 - val_accuracy: 0.6000 - val_loss: 0.6221\n",
      "Epoch 91/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0104 - val_accuracy: 0.6000 - val_loss: 0.6220\n",
      "Epoch 92/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0103 - val_accuracy: 0.6000 - val_loss: 0.6219\n",
      "Epoch 93/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0101 - val_accuracy: 0.6000 - val_loss: 0.6219\n",
      "Epoch 94/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0100 - val_accuracy: 0.6000 - val_loss: 0.6218\n",
      "Epoch 95/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0099 - val_accuracy: 0.6000 - val_loss: 0.6217\n",
      "Epoch 96/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0098 - val_accuracy: 0.6000 - val_loss: 0.6215\n",
      "Epoch 97/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0097 - val_accuracy: 0.6000 - val_loss: 0.6214\n",
      "Epoch 98/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0096 - val_accuracy: 0.6000 - val_loss: 0.6213\n",
      "Epoch 99/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 0.0095 - val_accuracy: 0.6000 - val_loss: 0.6212\n",
      "Epoch 100/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0094 - val_accuracy: 0.6000 - val_loss: 0.6211\n"
     ]
    }
   ],
   "source": [
    "vectorized_sentences = vectorize_layer(tf.constant(sentences_subset))\n",
    "# print(\"Shape of vectorized sentences:\", vectorized_sentences.shape)\n",
    "history = model.fit(\n",
    "    x=vectorized_sentences,\n",
    "    y=labels_subset,\n",
    "    epochs=100,\n",
    "    validation_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b14ed9",
   "metadata": {},
   "source": [
    "## Semantic Search Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "84da5b79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Shape of sentence embeddings: (100, 256, 128)\n",
      "\n",
      "First sentence's embedding vector:\n",
      " [[ 0.22146513 -0.2033522  -0.19967037 ... -0.17324048  0.24664827\n",
      "   0.1637163 ]\n",
      " [ 0.17540483 -0.20566894 -0.1328209  ... -0.13410693  0.22773775\n",
      "   0.1539578 ]\n",
      " [ 0.09272396 -0.05507018 -0.08153713 ... -0.02820148  0.10794813\n",
      "   0.07732717]\n",
      " ...\n",
      " [-0.0143142  -0.03834929  0.02532173 ...  0.04780747 -0.04444572\n",
      "  -0.01145894]\n",
      " [-0.0143142  -0.03834929  0.02532173 ...  0.04780747 -0.04444572\n",
      "  -0.01145894]\n",
      " [-0.0143142  -0.03834929  0.02532173 ...  0.04780747 -0.04444572\n",
      "  -0.01145894]]\n"
     ]
    }
   ],
   "source": [
    "# Create a new, simpler model for just embedding\n",
    "embedding_model = tf.keras.Sequential([\n",
    "    vectorize_layer,  # Use the trained layer from the previous model\n",
    "    model.get_layer('embedding_layer') # Use the trained embedding layer\n",
    "])\n",
    "\n",
    "# Use the predict method to get the embeddings for all sentences\n",
    "sentence_embeddings = embedding_model.predict(tf.constant(sentences_subset))\n",
    "\n",
    "print(\"Shape of sentence embeddings:\", sentence_embeddings.shape)\n",
    "print(\"\\nFirst sentence's embedding vector:\\n\", sentence_embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e408cb0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape of final sentence vectors: (100, 128)\n",
      "\n",
      "First sentence's final vector:\n",
      " [ 0.10998511 -0.10286884 -0.09105635 -0.10639376  0.08675896 -0.08225816\n",
      "  0.09703208 -0.09779937  0.0885028   0.09076387 -0.09070267  0.07294329\n",
      " -0.08416977 -0.10827542 -0.0849989  -0.09295622  0.07941282 -0.08442829\n",
      " -0.08182498 -0.09000168  0.0872865   0.077944    0.08419003  0.08106726\n",
      " -0.09847007 -0.09068771  0.09511352 -0.09476045  0.08152567  0.07642266\n",
      "  0.11498298 -0.08341417 -0.08682119 -0.08253176 -0.07601818 -0.10044832\n",
      "  0.09009997  0.10524737  0.10818671  0.09349973  0.11421166 -0.091021\n",
      " -0.08197806 -0.08877258 -0.08346443 -0.0856621  -0.10604051 -0.09587539\n",
      "  0.07972436  0.08886651  0.0839703   0.08055855  0.09821053 -0.09011839\n",
      "  0.07652532  0.07617205 -0.07606422 -0.07571373 -0.0847056   0.10338533\n",
      "  0.10668675  0.07981015  0.08427466 -0.083869   -0.1001945  -0.08383922\n",
      "  0.0940271  -0.080902    0.07483279 -0.09594051 -0.07697812  0.08428583\n",
      " -0.08554296  0.11250136 -0.08669924  0.09558922 -0.10021888 -0.08398913\n",
      " -0.0954331   0.10399583  0.10058685 -0.08481419 -0.07271922 -0.12053419\n",
      "  0.07810117  0.090105    0.11517871 -0.08115887  0.08332712 -0.08895\n",
      "  0.08628008 -0.07953542  0.08175417 -0.08783596  0.08282083 -0.08339416\n",
      "  0.08725798 -0.07547699 -0.08586809 -0.08051127 -0.08351963 -0.07897704\n",
      "  0.08868707 -0.07720024 -0.07879449  0.09798175 -0.08142511  0.11014219\n",
      "  0.07776745  0.10181368  0.09284454 -0.08896816  0.07974129 -0.09588952\n",
      "  0.08424259 -0.08887694 -0.08405938 -0.0762219  -0.079318    0.08293492\n",
      " -0.0779427   0.10296649 -0.09554717 -0.08973852 -0.07738617 -0.09250712\n",
      "  0.11080419  0.08069943]\n"
     ]
    }
   ],
   "source": [
    "# To get a single vector per sentence, we average the word vectors.\n",
    "# We need to handle the padded zeros, so we'll use a mask.\n",
    "\n",
    "# Get the mask from the embedding layer\n",
    "mask = embedding_model.get_layer('embedding_layer').compute_mask(vectorize_layer(tf.constant(sentences_subset)))\n",
    "\n",
    "# Apply the mask to the sentence embeddings to ignore padded zeros\n",
    "masked_embeddings = sentence_embeddings * np.expand_dims(mask, axis=-1)\n",
    "\n",
    "# Average the word embeddings to get one vector per sentence\n",
    "sentence_vectors = np.sum(masked_embeddings, axis=1) / np.sum(mask, axis=1, keepdims=True)\n",
    "\n",
    "print(\"\\nShape of final sentence vectors:\", sentence_vectors.shape)\n",
    "print(\"\\nFirst sentence's final vector:\\n\", sentence_vectors[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ffe04789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "(3,)\n",
      "Query: 'This movie was absolutely amazing and beautiful.'\n",
      "\n",
      "Top 3 similar sentences:\n",
      "Score: 0.0606 | Sentence: This movie was so badly written, directed and acte...\n",
      "Score: 0.0526 | Sentence: Are you familiar with concept of children's artwor...\n",
      "Score: 0.0525 | Sentence: An awful film! It must have been up against some r...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step(3,)\n",
      "Query: 'This movie was absolutely amazing and beautiful.'\n",
      "\n",
      "Top 3 similar sentences:\n",
      "Score: 0.0606 | Sentence: This movie was so badly written, directed and acte...\n",
      "Score: 0.0526 | Sentence: Are you familiar with concept of children's artwor...\n",
      "Score: 0.0525 | Sentence: An awful film! It must have been up against some r...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step(3,)\n",
      "Query: 'This movie was absolutely amazing and beautiful.'\n",
      "\n",
      "Top 3 similar sentences:\n",
      "Score: 0.0606 | Sentence: This movie was so badly written, directed and acte...\n",
      "Score: 0.0526 | Sentence: Are you familiar with concept of children's artwor...\n",
      "Score: 0.0525 | Sentence: An awful film! It must have been up against some r...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "(3,)\n",
      "\n",
      "Query: 'The acting was terrible and I hated the story.'\n",
      "\n",
      "Top 3 similar sentences:\n",
      "Score: 0.1490 | Sentence: I really enjoyed this movie.I was fifteen when this movie came out and I could relate. This will be a movie I would show my kids to let them know, the feelings they are having are normal. It is funny to see how we could be so devestated by things at such a young age..who knew that we would bounce back....again and again....Great movie!!!!\n",
      "Score: 0.1472 | Sentence: This movie is not just bad, not just corny, it is repulsive. Something about Daphne, about the creepy call-girl, about the whole damn (and I use the word literally) film radiates a grotesquery that would offend a brothel mistress. This film makes my skin crawl, makes me regret having reproductive organs, and makes me feel unclean.<br /><br />One of the things that bothers me most about this movie is that they used such a good concept. A creature that makes fantasies with disastrous results, rather than the cliché Worst Nightmare and the overdone Twisted Wish, is a truly fascinating film idea.<br /><br />Thought: The reason why hobgoblins need to be killed before day is that they are attracted to bright lights. During the day, bright lights don't show up well, so they could go anywhere.<br /><br />Count the Hobgoblins: Four hobgoblins drive out of the film studio, and yet at least nine of the pernicious plush-toys are killed throughout the course of the movie.<br /><br />Discussion Question: If you had a frigid, demanding, unappreciative girlfriend, would you enter garden-tool-combat with a military chunkhead? Explain.\n",
      "Score: 0.1423 | Sentence: This movie was so badly written, directed and acted that it beggars belief. It should be remade with a better script, director and casting service. The worst problem is the acting. You have Jennifer Beals on the one hand who is polished, professional and totally believable, and on the other hand, Ri'chard, who is woefully miscast and just jarring in this particular piece. Peter Gallagher and Jenny Levine are just awful as the slave owning (and keeping) couple, although both normally do fine work. The actors (and director) should not have attempted to do accents at all--they are inconsistent and unbelievable. Much better to have concentrated on doing a good job in actual English. The casting is ludicrous. Why have children of an \"African\" merchant (thus less socially desirable to the gens de couleur society ) been cast with very pale skinned actors, while the supposedly socially desirable Marcel, has pronounced African features, including an obviously dyed blond \"fro\"? It's as if the casting directors cannot be bothered to read the script they are casting and to chose appropriate actors from a large pool of extremely talented and physically diverse actors of color. It's just so weird! This could be a great movie and should be re-made, but with people who respect the material and can choose appropriate and skilled actors. There are plenty of good actors out there, and it would be fun to see how Jennifer Beals, Daniel Sunjata and Gloria Reuben would do with an appropriate cast, good script and decent direction.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "(3,)\n",
      "\n",
      "Query: 'The acting was terrible and I hated the story.'\n",
      "\n",
      "Top 3 similar sentences:\n",
      "Score: 0.1490 | Sentence: I really enjoyed this movie.I was fifteen when this movie came out and I could relate. This will be a movie I would show my kids to let them know, the feelings they are having are normal. It is funny to see how we could be so devestated by things at such a young age..who knew that we would bounce back....again and again....Great movie!!!!\n",
      "Score: 0.1472 | Sentence: This movie is not just bad, not just corny, it is repulsive. Something about Daphne, about the creepy call-girl, about the whole damn (and I use the word literally) film radiates a grotesquery that would offend a brothel mistress. This film makes my skin crawl, makes me regret having reproductive organs, and makes me feel unclean.<br /><br />One of the things that bothers me most about this movie is that they used such a good concept. A creature that makes fantasies with disastrous results, rather than the cliché Worst Nightmare and the overdone Twisted Wish, is a truly fascinating film idea.<br /><br />Thought: The reason why hobgoblins need to be killed before day is that they are attracted to bright lights. During the day, bright lights don't show up well, so they could go anywhere.<br /><br />Count the Hobgoblins: Four hobgoblins drive out of the film studio, and yet at least nine of the pernicious plush-toys are killed throughout the course of the movie.<br /><br />Discussion Question: If you had a frigid, demanding, unappreciative girlfriend, would you enter garden-tool-combat with a military chunkhead? Explain.\n",
      "Score: 0.1423 | Sentence: This movie was so badly written, directed and acted that it beggars belief. It should be remade with a better script, director and casting service. The worst problem is the acting. You have Jennifer Beals on the one hand who is polished, professional and totally believable, and on the other hand, Ri'chard, who is woefully miscast and just jarring in this particular piece. Peter Gallagher and Jenny Levine are just awful as the slave owning (and keeping) couple, although both normally do fine work. The actors (and director) should not have attempted to do accents at all--they are inconsistent and unbelievable. Much better to have concentrated on doing a good job in actual English. The casting is ludicrous. Why have children of an \"African\" merchant (thus less socially desirable to the gens de couleur society ) been cast with very pale skinned actors, while the supposedly socially desirable Marcel, has pronounced African features, including an obviously dyed blond \"fro\"? It's as if the casting directors cannot be bothered to read the script they are casting and to chose appropriate actors from a large pool of extremely talented and physically diverse actors of color. It's just so weird! This could be a great movie and should be re-made, but with people who respect the material and can choose appropriate and skilled actors. There are plenty of good actors out there, and it would be fun to see how Jennifer Beals, Daniel Sunjata and Gloria Reuben would do with an appropriate cast, good script and decent direction.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "(3,)\n",
      "\n",
      "Query: 'The acting was terrible and I hated the story.'\n",
      "\n",
      "Top 3 similar sentences:\n",
      "Score: 0.1490 | Sentence: I really enjoyed this movie.I was fifteen when this movie came out and I could relate. This will be a movie I would show my kids to let them know, the feelings they are having are normal. It is funny to see how we could be so devestated by things at such a young age..who knew that we would bounce back....again and again....Great movie!!!!\n",
      "Score: 0.1472 | Sentence: This movie is not just bad, not just corny, it is repulsive. Something about Daphne, about the creepy call-girl, about the whole damn (and I use the word literally) film radiates a grotesquery that would offend a brothel mistress. This film makes my skin crawl, makes me regret having reproductive organs, and makes me feel unclean.<br /><br />One of the things that bothers me most about this movie is that they used such a good concept. A creature that makes fantasies with disastrous results, rather than the cliché Worst Nightmare and the overdone Twisted Wish, is a truly fascinating film idea.<br /><br />Thought: The reason why hobgoblins need to be killed before day is that they are attracted to bright lights. During the day, bright lights don't show up well, so they could go anywhere.<br /><br />Count the Hobgoblins: Four hobgoblins drive out of the film studio, and yet at least nine of the pernicious plush-toys are killed throughout the course of the movie.<br /><br />Discussion Question: If you had a frigid, demanding, unappreciative girlfriend, would you enter garden-tool-combat with a military chunkhead? Explain.\n",
      "Score: 0.1423 | Sentence: This movie was so badly written, directed and acted that it beggars belief. It should be remade with a better script, director and casting service. The worst problem is the acting. You have Jennifer Beals on the one hand who is polished, professional and totally believable, and on the other hand, Ri'chard, who is woefully miscast and just jarring in this particular piece. Peter Gallagher and Jenny Levine are just awful as the slave owning (and keeping) couple, although both normally do fine work. The actors (and director) should not have attempted to do accents at all--they are inconsistent and unbelievable. Much better to have concentrated on doing a good job in actual English. The casting is ludicrous. Why have children of an \"African\" merchant (thus less socially desirable to the gens de couleur society ) been cast with very pale skinned actors, while the supposedly socially desirable Marcel, has pronounced African features, including an obviously dyed blond \"fro\"? It's as if the casting directors cannot be bothered to read the script they are casting and to chose appropriate actors from a large pool of extremely talented and physically diverse actors of color. It's just so weird! This could be a great movie and should be re-made, but with people who respect the material and can choose appropriate and skilled actors. There are plenty of good actors out there, and it would be fun to see how Jennifer Beals, Daniel Sunjata and Gloria Reuben would do with an appropriate cast, good script and decent direction.\n"
     ]
    }
   ],
   "source": [
    "from numpy.linalg import norm\n",
    "\n",
    "\n",
    "def find_similar_sentences(query_sentence, k=3):\n",
    "    # Step 1: Convert the query sentence to a single vector\n",
    "    query_vector_unshaped = embedding_model.predict(\n",
    "        tf.constant(np.array([query_sentence]))\n",
    "    )\n",
    "    query_vector = np.mean(query_vector_unshaped, axis=1)\n",
    "    query_vector = np.squeeze(query_vector)  # اضافه کردن این خط برای یک‌بعدی کردن\n",
    "\n",
    "    # Step 2: Calculate the Cosine Similarity between the query and all sentences\n",
    "    cosine_similarities = np.dot(sentence_vectors, query_vector) / (\n",
    "        norm(sentence_vectors, axis=1) * norm(query_vector)\n",
    "    )\n",
    "\n",
    "    # Step 3: Get the indices of the top k most similar sentences\n",
    "    top_k_indices = np.argsort(cosine_similarities)[::-1][:k]\n",
    "    print(top_k_indices.shape)  # باید (3,) باشد\n",
    "\n",
    "    # Step 4: Retrieve and return the sentences and their similarity scores\n",
    "    results = []\n",
    "    for index in top_k_indices:\n",
    "        results.append((cosine_similarities[index].round(4), sentences_subset[index]))\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# --- Test the function ---\n",
    "# Example 1: a sentence with a positive sentiment\n",
    "query_sentence_1 = \"This movie was absolutely amazing and beautiful.\"\n",
    "similar_sentences_1 = find_similar_sentences(query_sentence_1)\n",
    "print(f\"Query: '{query_sentence_1}'\")\n",
    "print(\"\\nTop 3 similar sentences:\")\n",
    "for score, sentence in similar_sentences_1:\n",
    "    print(f\"Score: {score:.4f} | Sentence: {str(sentence)[:50]}...\")\n",
    "\n",
    "# Example 2: a sentence with a negative sentiment\n",
    "query_sentence_2 = \"The acting was terrible and I hated the story.\"\n",
    "similar_sentences_2 = find_similar_sentences(query_sentence_2)\n",
    "print(f\"\\nQuery: '{query_sentence_2}'\")\n",
    "print(\"\\nTop 3 similar sentences:\")\n",
    "for score, sentence in similar_sentences_2:\n",
    "    print(f\"Score: {score:.4f} | Sentence: {sentence}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8947b740",
   "metadata": {},
   "source": [
    "## Emotion Classifier System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "11a77816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "[[0.9509964]]\n",
      "[[0.9509964]]\n",
      "[[0.9509964]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Positive', array([[0.9509964]], dtype=float32))"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict_sentiment(sentence):\n",
    "    # The model expects a batch of sentences, so we wrap the single sentence in a list\n",
    "    vectorized_phrase = vectorize_layer(tf.constant([sentence]))\n",
    "    prediction_score = model.predict(vectorized_phrase)\n",
    "    print(prediction_score)\n",
    "\n",
    "    if prediction_score >= 0.5:\n",
    "        sentiment = \"Positive\"\n",
    "    else:\n",
    "        sentiment = \"Negative\"\n",
    "\n",
    "    return sentiment, prediction_score\n",
    "\n",
    "\n",
    "predict_sentiment(\"everything is well. i liked it!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
